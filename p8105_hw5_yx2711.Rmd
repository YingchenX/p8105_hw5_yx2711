---
title: "p8105_hw5_yx2711"
author: "Yingchen Xu"
date: "2022-11-15"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


# Problem 1 


Use the `list.files()` function to create the dataframe containing all file names.
Use the `map()` function to iterate file names, read in the data, and save the result as `full_df`.
```{r, message = FALSE}
full_df = 
  tibble(
    files = list.files("hw5_data/data/"),
    path = str_c("hw5_data/data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```


Tidy the results using `mutate()` and `pivot_longer()`.
```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```


Make a spaghetti plot showing each subject overtime.
```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

There is a within-subject correlation. Subjects in the control groups do not have a specific trend in change overtime, while subjects in the experimental group have a linear increase in general. 


# Problem 2

```{r}
homicide = read.csv("data/homicide-data.csv") %>% 
  janitor::clean_names() 
```

The raw dataset contain `r nrow(homicide)` observations and `r ncol(homicide)` variables. The key variables are uid, reported_date, victims' names, race, age, sex, city, state, longitude and latitude, and one disposition variable indicating the arrest status of the victims. The raw dataset summarizes homicides data in `r homicide %>% select(state) %>% distinct %>% count` states and `r homicide %>% select(city) %>% distinct %>% count` cities.


Use `mutate()` to create the new variable `city_state` and recode the possible typo of `Tulsa, AL` to `Tulsa, OK`.
Create the summary table of the total number of homicides and the number of unsolved homicides.
```{r}
homicide = homicide %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    city_state = recode(city_state, "Tulsa, AL" = "Tulsa, OK")
  )


summary = homicide %>% 
  group_by(city_state) %>% 
  summarize(
    total_number = n(),
    total_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")
  ))

summary %>% knitr::kable()

```

The above table summarizes within cities the total number of homicides indicating by `total_number` and the number of unsolved homicides indicating by `total_unsolved`.



Use `prop.test()` function to estimate the proportion of unsolved homicides in Baltimore, MD.
```{r}

baltimore_test = prop.test(
    summary %>% filter(city_state == "Baltimore, MD") %>% pull(total_unsolved),
    summary %>% filter(city_state == "Baltimore, MD") %>% pull(total_number)
    ) %>% 
  broom::tidy()

baltimore_test %>% 
  select(estimate, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)

```

The estimate of proportion of homicides that are unsolved in Baltimore is `r baltimore_test %>% select(estimate)` (95% CI: `r baltimore_test %>% select(conf.low)` to `r baltimore_test %>% select(conf.high)`).


Write a `function(x)` for repeating the process of prop.test.

```{r}

prop_test = function(x){
  
  summary = x %>% 
  group_by(city_state) %>% 
  summarize(
    total_number = n(),
    total_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")
  ))
  
  city_test = prop.test(
    summary %>% pull(total_unsolved),
    summary %>% pull(total_number)
    ) %>% 
  broom::tidy()
  
  city_test
  
}
```


Nesting the unrelated columns.
Map the nested data to the function `prop_test` to iterate the process of proportional testing. 
```{r}

homicide_nest = homicide %>%
  nest(data = uid:city_state)


##### Mapping unsuccessful. Need to work on it later.
# homicide_test = homicide_nest %>% 
#  mutate(test = map(data, prop_test)) %>% 
#  unnest() %>% 
#  broom::tidy() %>% 
#  select(estimate, conf.low, conf.high) %>% 
#  knitr::kable(digits = 3)

```


Create a plot that shows the estimates and CI for each city
```{r, eval=FALSE}
homicide_test %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "The estimates and CIs for proportion of unsolved homicides for each city",
    x = "City, State",
    y = "Estimate Proportion")
```

Need interpretation of graph.


# Problem 3

First write down the function to simulate data from a normal distribution, run a t.test, and return the estimates of t-statistics and p-value.
```{r}
t_test = function(n = 30, mu, sigma = 5) {
  
  x = rnorm(n, mean = mu, sd = sigma)
  
  
  t_test =
    t.test(x, mu = 0) %>% 
    broom::tidy() 
  
  t_test %>% 
    select(estimate, p.value)
  
}
```


Then, generate 5000 datasets from `rnorm()` and run the `t_test` for mu = 0.
Save the resulting estimate and p-value as `sim_mu0_df`.
```{r}

sim_mu0_df = 
  expand_grid(
    true_mu = 0,
    iter = 1:5000
  ) %>% 
  mutate(
    estimate_df = map(.x = true_mu, ~ t_test(mu = .x))
  ) %>% 
  unnest()

```



